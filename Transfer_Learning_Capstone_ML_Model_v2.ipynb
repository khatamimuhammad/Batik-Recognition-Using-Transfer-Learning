{"cells":[{"cell_type":"markdown","metadata":{"id":"pIgsO4HmLx2k"},"source":["# **Download the dataset**\n","Link to our datasets :\n","\n","https://universe.roboflow.com/scripsweet/motif-batik-dga55/dataset/1\n","\n","https://www.kaggle.com/datasets/alfanme/indonesian-batik-motifs-corak-app/data\n","\n","We use both of them and combine them so that our model can have more data to train and help increase its accuracy.\n","\n","**First we need to download the combined version. **\n","\n","We download it in this link : https://drive.google.com/file/d/1tWiO8DN1IHmImCWz2EVgERROpYSIC5Ot/view?usp=sharing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZqlTPOFRLvkj"},"outputs":[],"source":["# Run this code to download the dataset\n","!gdown 1tWiO8DN1IHmImCWz2EVgERROpYSIC5Ot"]},{"cell_type":"markdown","metadata":{"id":"-3t8YB1TOLpO"},"source":["Then we will extract it to the current directory"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKeEXMgsOTVX"},"outputs":[],"source":["# Run this code to extract the file\n","import zipfile\n","\n","dataset_zip = './raw_batik_v2.1.zip'\n","zip_read = zipfile.ZipFile(dataset_zip, 'r')\n","zip_read.extractall()\n","zip_read.close()"]},{"cell_type":"markdown","metadata":{"id":"g9WmXHOHVN5m"},"source":["**Checking the contents of the folder**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y534wJEoVXku"},"outputs":[],"source":["import os\n","\n","base_dir = './raw_batik_v2.1'\n","\n","print(\"Content of base directory:\")\n","print(os.listdir(base_dir))\n","\n","print(\"\\nContent of train directory:\")\n","print(os.listdir(f'{base_dir}/train'))\n","\n","print(\"\\nContent of test directory:\")\n","print(os.listdir(f'{base_dir}/test'))"]},{"cell_type":"markdown","metadata":{"id":"bfYnHmohW2I5"},"source":["Create variable for shortcut of **train and test path**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zn5WzUsmW-Fv"},"outputs":[],"source":["train_dir = os.path.join(base_dir, 'train')\n","test_dir = os.path.join(base_dir, 'test')"]},{"cell_type":"markdown","metadata":{"id":"b3UpkQoeWDIn"},"source":["Checking total images in every sub-directory of **train**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p09WOXEkWXjg"},"outputs":[],"source":["for folder in os.listdir(train_dir):\n","    sub_dir = os.path.join(train_dir, folder)\n","    if os.path.isdir(sub_dir):  # Check if it's a directory\n","        # List only image files in the subdirectory\n","        image_files = [f for f in os.listdir(sub_dir) if os.path.isfile(os.path.join(sub_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))]\n","        print(f'{folder} : {len(image_files)} images')"]},{"cell_type":"markdown","metadata":{"id":"3BAgVnI9Y2-t"},"source":["Checking total images in every sub-directory of **test**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3oaagsFwY7o4"},"outputs":[],"source":["for folder in os.listdir(test_dir):\n","    sub_dir = os.path.join(test_dir, folder)\n","    if os.path.isdir(sub_dir):  # Check if it's a directory\n","        # List only image files in the subdirectory\n","        image_files = [f for f in os.listdir(sub_dir) if os.path.isfile(os.path.join(sub_dir, f)) and f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp', '.tiff'))]\n","        print(f'{folder} : {len(image_files)} images')"]},{"cell_type":"markdown","metadata":{"id":"eJCT8pLwb51X"},"source":["# **Building the Model**"]},{"cell_type":"markdown","metadata":{"id":"5ybid3L5PGTx"},"source":["1. Import Library yang Dibutuhkan :\n","    - tensorflow\n","    - numpy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uA0CoocPGTx"},"outputs":[],"source":["# Tensorflow\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Additional Library\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"diIsazOsPGTy"},"source":["2. Pra-Pemrosesan Data\n","    Kita akan menggunakan ImageDataGenerator untuk melakukan pra-pemrosesan data dan augmentasi gambar."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PCwX1tSpPGTy"},"outputs":[],"source":["# Pra-Pemrosesan Data\n","train_datagen = ImageDataGenerator(\n","                    rescale=1.0/255.0,\n","                    rotation_range=20,\n","                    width_shift_range=0.2,\n","                    height_shift_range=0.2,\n","                    # brightness_range=[0.8,1.2],\n","                    zoom_range=0.6,\n","                    horizontal_flip=True,\n","                    shear_range = 0.2,\n","                    fill_mode = 'nearest')\n","\n","test_datagen = ImageDataGenerator(\n","                    rescale=1.0/255.0,)\n","                    # rotation_range=20,\n","                    # width_shift_range=0.2,\n","                    # height_shift_range=0.2,\n","                    # # brightness_range=[0.8,1.2],\n","                    # #zoom_range=0.,\n","                    # horizontal_flip=True,\n","                    # shear_range = 0.2,\n","                    # fill_mode = 'nearest')"]},{"cell_type":"markdown","metadata":{"id":"IkI8LFSvPGVJ"},"source":["3. Persiapan Data Latih yang akan Dipelajari oleh Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgOQ1_d9PGVJ"},"outputs":[],"source":["train_generator = train_datagen.flow_from_directory(\n","        train_dir,\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='sparse',\n","        shuffle=True)\n","\n","validation_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(224, 224),\n","        batch_size=32,\n","        class_mode='sparse')"]},{"cell_type":"markdown","metadata":{"id":"TqXZhKu6fYwE"},"source":["## **Creating the model**"]},{"cell_type":"markdown","metadata":{"id":"EYYTZ2yWPGVL"},"source":["## **Transfer learning**"]},{"cell_type":"markdown","metadata":{"id":"rGkRou9mPGVL"},"source":["###################################################### Transfer Learning #########################################################################"]},{"cell_type":"markdown","metadata":{"id":"o-iGPb_BPGVL"},"source":["Import library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d1mqrGgLPGVL"},"outputs":[],"source":["from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7WuclA05PGVM"},"outputs":[],"source":["# Load model VGG16 sebagai base model\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X4a6UrjqPGVM"},"outputs":[],"source":["# Fine-tuning beberapa layer terakhir\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","base_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j1arU5MdGTrf"},"outputs":[],"source":["# Mengurangi layers pada PreTrained Model\n","reduced_pre_trained_model = Model(base_model.input, base_model.layers[-7].output)\n","reduced_pre_trained_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-22MdNZGPGVM"},"outputs":[],"source":["# Tambahkan layer baru\n","x = reduced_pre_trained_model.output\n","x = tf.keras.layers.BatchNormalization()(x)\n","x = tf.keras.layers.Conv2D(512, (3,3), activation='relu')(x)\n","x = tf.keras.layers.Conv2D(512, (3,3), activation='relu')(x)\n","x = tf.keras.layers.MaxPool2D(2,2)(x)\n","x = tf.keras.layers.Conv2D(1024, (3,3), activation='relu')(x)\n","x = tf.keras.layers.Conv2D(1024, (3,3), activation='relu')(x)\n","x = tf.keras.layers.MaxPool2D(2,2)(x)\n","\n","x = tf.keras.layers.Flatten()(x)\n","x = tf.keras.layers.Dense(512, activation='relu')(x)\n","x = tf.keras.layers.Dropout(0.5)(x)  # Naikkan nilai dropout\n","predictions = tf.keras.layers.Dense(25, activation='softmax')(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mkLHi-puPGVN"},"outputs":[],"source":["# Gabungkan base model dan layer baru\n","model = Model(inputs=reduced_pre_trained_model.input, outputs=predictions)\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Dm08dB4PGVN"},"outputs":[],"source":["# Ubah parameter optimizer\n","opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n","opt2 = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","opt3 = tf.keras.optimizers.SGD(learning_rate=0.001)\n","\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=opt2,\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"rWOW7Q5xPGVO"},"source":["3. Latih Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0rIdaT0PGVO"},"outputs":[],"source":["import os\n","os.environ['KMP_DUPLICATE_LIB_OK']='True'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZNFtNCQ_PGVO"},"outputs":[],"source":["# Tambahkan early stopping dan model checkpoint\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)\n","model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zhu7qwSEPGVP"},"outputs":[],"source":["# Latih Model\n","history = model.fit(\n","      train_generator,\n","      steps_per_epoch=10,\n","      epochs=100,\n","      validation_data=validation_generator,\n","      validation_steps=5,\n","      verbose=2,)\n","      #callbacks=[early_stopping, model_checkpoint])"]},{"cell_type":"markdown","metadata":{"id":"aYdu1hTUPGVU"},"source":["Plot akurasi training dan validasi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjwVm8FTPGVU"},"outputs":[],"source":["plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='Training Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"P_G_fVA3fnxK"},"source":["## **Model Prediction**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYaUHyaEJ7Bj"},"outputs":[],"source":["# this is if we running on google colab or if we do not have keras-preprocessing module\n","!pip install keras-preprocessing\n","!!pip install tensorflowjs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zlbizHb77dui"},"outputs":[],"source":["# save only the model\n","model.save('model_v2.h5')\n","\n","# save model with tf js\n","!tensorflowjs_converter --input_format=keras model_v2.h5 tfjs_model\n","\n","!zip -r tfjs_model.zip tfjs_model"]},{"cell_type":"markdown","metadata":{"id":"h8RUwVzU7duj"},"source":["## Work only on google colab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W7o3_74LN0mN"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","import matplotlib.pyplot as plt\n","import os\n","from google.colab import files\n","\n","# Load the trained model\n","# model = tf.keras.models.load_model('best_model.h5')\n","\n","# Directory where your test images are located\n","test_images_dir = os.path.join('./fixed-dataset', 'test')\n","\n","# Get a list of all the subdirectories (classes)\n","classes = os.listdir(test_images_dir)\n","\n","# Function to preprocess the image for prediction\n","def preprocess_image(img_path):\n","    img = image.load_img(img_path, target_size=(224, 224))  # Resize the image to the target size\n","    img_array = image.img_to_array(img)  # Convert the image to a numpy array\n","    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match the input shape of the model\n","    img_array /= 255.0  # Normalize the image\n","    return img_array\n","\n","# Function to make predictions\n","def predict_image(img_path):\n","    img_array = preprocess_image(img_path)\n","    predictions = model.predict(img_array)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nx3oND9kLdec"},"outputs":[],"source":["uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","    # predicting images\n","    path = fn\n","    predictions = predict_image(path)\n","    predicted_class = np.argmax(predictions, axis=1)[0]  # Get the class with the highest probability\n","    predicted_class_name = classes[predicted_class]  # Map index to class name\n","\n","    # Print the predicted class\n","    print(f'Image: {path}, Predicted class: {predicted_class_name}')\n","\n","    # Optionally, plot the image and the predicted class\n","    img = image.load_img(path, target_size=(224, 224))\n","    plt.imshow(img)\n","    plt.title(f'Predicted class: {predicted_class_name}')\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"VAx0460ZURkG"},"source":["# **Clean UP**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yGaNHqVrUQu7"},"outputs":[],"source":["import os, signal\n","\n","# !rm -rf 'raw_batik_v2.1'\n","# !rm -rf 'raw_batik_v2.1.zip'\n","os.kill(os.getpid(), signal.SIGKILL)"]},{"cell_type":"markdown","metadata":{"id":"veh2kCFPNWzm"},"source":["\\"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}